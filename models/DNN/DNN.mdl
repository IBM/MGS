// =================================================================
// Licensed Materials - Property of IBM
//
// "Restricted Materials of IBM"
//
// BCM-YKT-07-18-2017
//
// (C) Copyright IBM Corp. 2005-2017  All rights reserved
//
// US Government Users Restricted Rights -
// Use, duplication or disclosure restricted by
// GSA ADP Schedule Contract with IBM Corp.
//
// =================================================================

#ifndef DNN_MDL
#define DNN_MDL
#include "./DNNTools.mdl"

Node DNNode Implements ForwardProducer, BackwardProducer {
//{{{
   double output;
   double gradient;
   EdgeSetInput [] inputs;
   double* weightedGradient;
   bool ready;
   
   //Shared {
   //  InitPhase initializeShared(); //to printout debug purpose
   //}
   InitPhase initialize();
   RuntimePhase update(output, gradient);

   ForwardProducer.forward << &output;
   BackwardProducer.backward << &gradient;

   InAttrPSet {
     string identifier;
     unsigned index;
   }

   UserFunction extractInputIndex;

   Connection Pre Node (PSet.identifier=="input") Expects ForwardArrayProducer {
      ForwardArrayProducer.forwardArray >> inputs.inputArray;
      extractInputIndex();
   }

   Connection Pre Node (PSet.identifier=="gradient") Expects BackwardProducer {
      BackwardProducer.backward >> weightedGradient;
   }
//}}}
}

Node DNEdgeSet Implements ForwardArrayProducer, BackwardProducer {
//{{{
   double [] weights;
   double [] deltaWeights;
   double [] deltaWeightsSquared;
   double [] weightedOutputs;
   double weightedGradient;
   double [] echoes;
   unsigned echoIndex;
   double biasCorrectionW;
   double biasCorrectionS;

   //double* bias;
   double* input;
   double* [] gradients;

   bool readyForward;
   bool readyBackward;

   string transferFunctionName;

   bool momentum;
   bool rmsprop;

   Shared {
     double eta; //learn rate
     double alpha;
     double beta;
     int max_num_layers; //TRICK: we use this as maximum size for pre-allocating 'echoes' data
     string [] optimization;
     InitPhase initializeShared(); //to setup the size for echoes[]
   }

   InitPhase initialize();
   RuntimePhase update(weightedOutputs, weightedGradient);

   ForwardArrayProducer.forwardArray << &weightedOutputs;
   BackwardProducer.backward << &weightedGradient;
   
   InAttrPSet {
     string identifier;
   }

   Connection Pre Node (PSet.identifier=="input") Expects ForwardProducer {
      ForwardProducer.forward >> input;
   }

   Connection Pre Constant (PSet.identifier=="bias") Expects ForwardProducer {
      ForwardProducer.forward >> input;
      //ForwardProducer.forward >> bias;
   }

   Connection Pre Node (PSet.identifier=="gradient") Expects BackwardProducer {
      BackwardProducer.backward >> gradients;
   }
//}}}
}


/* The supervisor does two jobs
  1. keeps feeding the input to the first layer [which is done by the first supervisor node as the input is at the SHARED data 'x']

  2. compute the gradient for the last layer's DNNode
-> as this gradient is NOT available until the 'compute' of the data passing through all layers and get to this last layer's DNNode
  which takes 'N' steps - with N is the depth of the DNN
  the supervisor needs to buffers the expected label into a N-side array 'labels'
*/
Node SupervisorNode Implements BackwardProducer, ForwardArrayProducer {
//{{{
  double primaryGradient;
  double* [] logits;
  double [] predictions; //the softmax
  double sumOfSquaredError;
  unsigned wins;
  bool ready;

  Shared {
    //{{{
    string transferFunctionName; //the transfer function to be used by ALL nodes
    unsigned [] labels; //buffers the expected output until it can compute the gradients for the associated input 
    unsigned labelIndex; //the index to the label being processed in the above array '[] labels'
    unsigned numberOfInputs;
    unsigned numberOfLabels;
    double []* x;
    bool shready;

    string dataLocation;
    bool test;
    bool refreshErrors;
    unsigned trainingEpoch; //current epoch index
    unsigned trainingEpochs; //total epochs
    unsigned imageIndex; //current index in 0...numImages
      //However, the real image to be processed is 
      //the one with index _shuffledDeck(imageIndex);

    InitPhase initializeShared;
    RuntimePhase updateShared;
    //}}}
  }

   InitPhase initialize();
   RuntimePhase update(primaryGradient);

   ForwardArrayProducer.forwardArray << Shared.x;
   BackwardProducer.backward << &primaryGradient;

   InAttrPSet {
     string identifier;
   }

   Connection Pre Node (PSet.identifier=="input") Expects ForwardProducer {
      ForwardProducer.forward >> logits;
   }
//}}}
}


#endif
